# main.py
import os
import requests
import json
import random
import re
from datetime import datetime
from twitter_api import TwitterClient
import urllib.parse

# New imports
import textwrap
import base64
from instagrapi import Client
from PIL import Image, ImageDraw, ImageFont
import time

# Environment variables (set in GitHub Secrets)
NEWS_API_KEY = os.environ.get("NEWS_API_KEY")
TWITTER_API_KEY = os.environ.get("TWITTER_API_KEY")
TWITTER_API_SECRET = os.environ.get("TWITTER_API_SECRET")
TWITTER_ACCESS_TOKEN = os.environ.get("TWITTER_ACCESS_TOKEN")
TWITTER_ACCESS_TOKEN_SECRET = os.environ.get("TWITTER_ACCESS_TOKEN_SECRET")

# Instagram credentials / session
INSTA_USERNAME = os.environ.get("INSTA_USERNAME")
INSTA_PASSWORD = os.environ.get("INSTA_PASSWORD")
# Optional: base64-encoded session JSON (set in Secrets) so CI doesn't need interactive login
INSTA_SESSION_BASE64 = os.environ.get("INSTA_SESSION_BASE64")
INSTA_SESSION_FILE = os.environ.get("INSTA_SESSION_FILE", "insta_session.json")

# Initialize Twitter client (unchanged)
twitter = TwitterClient(
    TWITTER_API_KEY, TWITTER_API_SECRET,
    TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET
)

# --- your existing constants / functions (unchanged) ---
COUNTRIES = ["us", "gb", "ca", "au", "in", "fr", "de", "jp", "cn", "br"]
SOURCES = ["bbc-news", "al-jazeera-english", "reuters", "cnn", "the-guardian-uk"]

def load_posted_urls():
    try:
        with open("posted_articles.json", "r", encoding='utf-8') as f:
            content = f.read().strip()
            print(f"ğŸ“‚ Content of posted_articles.json: {content}")
            if not content:
                print("ğŸ“‚ posted_articles.json is empty, initializing with []")
                return []
            return [urllib.parse.unquote(url.encode().decode('unicode_escape')) for url in json.loads(content)]
    except (json.JSONDecodeError, FileNotFoundError) as e:
        print(f"ğŸ“‚ Error loading posted_articles.json: {str(e)}. Initializing with []")
        with open("posted_articles.json", "w", encoding='utf-8') as f:
            json.dump([], f)
        return []

def save_posted_url(url):
    posted_urls = load_posted_urls()
    decoded_url = urllib.parse.unquote(url.encode().decode('unicode_escape'))
    posted_urls.append(decoded_url)
    with open("posted_articles.json", "w", encoding='utf-8') as f:
        json.dump(posted_urls[-100:], f)

def fetch_news():
    if not NEWS_API_KEY:
        print("âŒ NEWS_API_KEY not found. Using mock data...")
        return create_mock_article()
    posted_urls = load_posted_urls()
    queries = [
        f"https://newsapi.org/v2/top-headlines?category=general&language=en&apiKey={NEWS_API_KEY}",
        *[f"https://newsapi.org/v2/top-headlines?category=general&language=en&country={country}&apiKey={NEWS_API_KEY}" for country in COUNTRIES],
        f"https://newsapi.org/v2/everything?q=news&language=en&sortBy=publishedAt&apiKey={NEWS_API_KEY}",
        *[f"https://newsapi.org/v2/top-headlines?sources={source}&apiKey={NEWS_API_KEY}" for source in SOURCES]
    ]
    for url in queries:
        try:
            response = requests.get(url, timeout=10)
            print(f"ğŸŒ NewsAPI request: {url.replace(NEWS_API_KEY, '***')}")
            if response.status_code != 200:
                print(f"âŒ NewsAPI error: {response.status_code} {response.text}")
                continue
            data = response.json()
            articles = data.get("articles", [])
            if not articles:
                print(f"ğŸ“° No articles found for {url}")
                continue
            available_articles = [
                a for a in articles
                if a.get("url") and urllib.parse.unquote(a["url"].encode().decode('unicode_escape')) not in posted_urls and a.get("title") and len(a.get("title", "")) > 10
            ]
            if not available_articles:
                print(f"ğŸ“° No new quality articles available for {url}")
                continue
            article = random.choice(available_articles)
            print(f"âœ… Selected article: {article['title']}")
            return {
                "title": (article.get("title") or "Untitled News").strip(),
                "description": (article.get("description") or "").strip(),
                "content": (article.get("content") or "").strip(),
                "url": urllib.parse.unquote(article.get("url").encode().decode('unicode_escape') or "").strip(),
                "published_at": article.get("publishedAt", datetime.utcnow().isoformat())
            }
        except Exception as e:
            print(f"âŒ Error fetching news from {url}: {str(e)}")
            continue
    print("ğŸ“° All queries failed, using mock article")
    return create_mock_article()

def create_mock_article():
    mock_articles = [
        {
            "title": "Tech Innovation Surges Globally",
            "description": "Companies push AI and sustainability.",
            "content": "Tech firms invest heavily in AI. Green tech drives growth. Efficiency improves with new tools. Industries adopt eco-solutions. Global markets evolve rapidly. Updates are ongoing. Stay informed.",
            "url": "https://example.com/tech-news",
            "published_at": datetime.utcnow().isoformat()
        },
        {
            "title": "Climate Summit Sets New Goals",
            "description": "Leaders pledge carbon cuts.",
            "content": "Summit agreements reduce emissions. Countries boost green projects. Funding increases for sustainability. Climate action is key. Progress is tracked globally. More details to come. Stay updated.",
            "url": "https://example.com/climate-news",
            "published_at": datetime.utcnow().isoformat()
        }
    ]
    return random.choice(mock_articles)

def generate_hashtags(text):
    words = text.lower().split()
    stop_words = {'the', 'and', 'that', 'this', 'with', 'from', 'they', 'have', 'been', 'said', 'will', 'would', 'could', 'should', 'news', 'more', 'than', 'when', 'where', 'what', 'which', 'their'}
    keywords = [word.strip(".,!?()[]{}\"\'") for word in words if len(word) > 4 and word.isalpha() and word not in stop_words]
    hashtags = [f"#{word.capitalize()}" for word in list(dict.fromkeys(keywords))[:1]]
    trending = random.sample([
        "#BreakingNews", "#GlobalNews", "#Headlines", "#TechUpdate", "#SpaceNews"
    ], 2)
    return hashtags + trending + ["#verixanews", "#verixa"]

def summarize_text(text, max_sentences=5):
    sentences = re.split(r'(?<=[.!?]) +', text.strip())
    return " ".join(sentences[:max_sentences])

def trim_to_twitter_limit(text, url, hashtags):
    hashtag_str = " ".join(hashtags)
    max_len = 280 - (len(url) + len(hashtag_str) + 18)
    sentences = re.split(r'(?<=[.!?]) +', text)
    trimmed = ""
    for s in sentences:
        if len(trimmed) + len(s) + 1 <= max_len:
            trimmed += (s + " ")
        else:
            break
    return trimmed.strip()

def create_tweet(article):
    title = article.get('title', 'Breaking News')
    description = article.get('description', '').strip()
    content = article.get('content', '').strip()
    url = urllib.parse.unquote(article.get('url', 'https://example.com').encode().decode('unicode_escape'))
    raw_text = f"{title}. {description} {content}".strip()
    summary = summarize_text(raw_text, max_sentences=6)
    hashtags = generate_hashtags(raw_text)[:4]
    clean_summary = trim_to_twitter_limit(summary, url, hashtags)
    tweet = f"{clean_summary}\nRead full article - {url}\n{' '.join(hashtags)}"
    print(f"ğŸ“ Generated tweet ({len(tweet)} chars):\n{'-' * 50}\n{tweet}\n{'-' * 50}")
    return tweet

# ---------------- New Instagram functions ----------------

def _maybe_write_session_file_from_base64():
    """If INSTA_SESSION_BASE64 is provided (GitHub Actions secret), decode it to session file."""
    if INSTA_SESSION_BASE64 and not os.path.exists(INSTA_SESSION_FILE):
        try:
            data = base64.b64decode(INSTA_SESSION_BASE64)
            with open(INSTA_SESSION_FILE, "wb") as f:
                f.write(data)
            print(f"ğŸ” Wrote Instagram session file to {INSTA_SESSION_FILE} from INSTA_SESSION_BASE64")
        except Exception as e:
            print("âš ï¸ Failed to decode INSTA_SESSION_BASE64:", e)

def get_instagram_client():
    """Return a logged-in instagrapi.Client or None on failure."""
    if not INSTA_USERNAME or not INSTA_PASSWORD:
        print("âš ï¸ INSTA_USERNAME or INSTA_PASSWORD not set; skipping Instagram.")
        return None

    _maybe_write_session_file_from_base64()

    client = Client()
    try:
        # If session file exists, try to load it first
        if os.path.exists(INSTA_SESSION_FILE):
            try:
                client.load_settings(INSTA_SESSION_FILE)
                # Attempt login (this will reuse session if valid)
                client.login(INSTA_USERNAME, INSTA_PASSWORD)
                client.dump_settings(INSTA_SESSION_FILE)
                print("ğŸ” Instagram: logged in using saved session/settings.")
                return client
            except Exception as e:
                print("âš ï¸ Saved IG session failed; will attempt fresh login:", e)

        # Fresh login and dump session
        client = Client()
        client.login(INSTA_USERNAME, INSTA_PASSWORD)
        client.dump_settings(INSTA_SESSION_FILE)
        print("ğŸ” Instagram: fresh login succeeded and session saved.")
        return client
    except Exception as e:
        print("âŒ Instagram login/initialization failed:", e)
        return None

def create_news_image(headline, url=None, output_path="news_post.jpg"):
    """Generate a simple professional news-style image (1080x1080)."""
    W, H = 1080, 1080
    bg_color = (18, 18, 18)
    accent_color = (200, 35, 45)  # red bar
    text_color = (255, 255, 255)
    meta_color = (180, 180, 180)

    img = Image.new("RGB", (W, H), bg_color)
    draw = ImageDraw.Draw(img)

    # Try some common system fonts; fall back to default if none available
    fonts_to_try = ["DejaVuSans-Bold.ttf", "arialbd.ttf", "Arial.ttf", "LiberationSans-Bold.ttf"]
    header_font = None
    title_font = None
    url_font = None
    for f in fonts_to_try:
        try:
            header_font = ImageFont.truetype(f, 36)
            title_font = ImageFont.truetype(f, 64)
            url_font = ImageFont.truetype(f, 28)
            break
        except Exception:
            continue
    if header_font is None:
        header_font = ImageFont.load_default()
        title_font = ImageFont.load_default()
        url_font = ImageFont.load_default()

    # Top "BREAKING NEWS" bar
    draw.rectangle([(0, 0), (W, 120)], fill=accent_color)
    header_text = "BREAKING NEWS"
    draw.text((30, 34), header_text, font=header_font, fill=(255, 255, 255))

    # Wrap headline text to multiple lines
    # width param controls wrap; tune if you need fewer/more chars per line
    wrap_width = 24
    wrapped = textwrap.wrap(headline, wrap_width)
    # compute total height
    line_heights = []
    max_line_width = 0
    for line in wrapped:
        w, h = draw.textsize(line, font=title_font)
        line_heights.append((w, h))
        if w > max_line_width:
            max_line_width = w
    total_text_height = sum(h for (_, h) in line_heights) + (len(line_heights) - 1) * 8

    # Start drawing headline vertically centered (but a bit lower to leave top bar)
    y_start = (H - total_text_height) // 2 + 30
    for i, line in enumerate(wrapped):
        w, h = line_heights[i]
        x = (W - w) // 2
        draw.text((x, y_start), line, font=title_font, fill=text_color)
        y_start += h + 8

    # Draw URL / source at bottom-left
    if url:
        try:
            domain = re.sub(r"^https?://", "", url).split("/")[0]
            draw.text((40, H - 60), domain, font=url_font, fill=meta_color)
        except Exception:
            draw.text((40, H - 60), url, font=url_font, fill=meta_color)

    # Save image
    img.save(output_path, quality=85, optimize=True)
    print(f"ğŸ–¼ News image created at {output_path}")
    return output_path

def post_to_instagram(image_path, caption):
    """Upload image to Instagram and return True on success, False otherwise."""
    client = get_instagram_client()
    if client is None:
        print("âš ï¸ Instagram client not available; skipping upload.")
        return False
    try:
        # Use photo_upload (instagrapi handles resizing if needed)
        media = client.photo_upload(image_path, caption)
        print(f"âœ… Posted to Instagram (pk={getattr(media, 'pk', 'unknown')})")
        return True
    except Exception as e:
        print("âŒ Instagram upload failed:", e)
        return False

# ---------------- end Instagram functions ----------------

def main():
    try:
        print("ğŸ¤– Starting AI News Agent...")
        print("ğŸ“° Fetching news...")
        article = fetch_news()
        print("âœï¸ Creating tweet...")
        tweet = create_tweet(article)
        print("ğŸ“¤ Posting tweet...")
        twitter.post_tweet(tweet)
        print("âœ… Tweet posted successfully!")
        if article.get("url"):
            save_posted_url(article["url"])
            print(f"ğŸ’¾ Saved article URL to history")

        # ---- New: create image + post to Instagram ----
        try:
            # headline: prefer article title, otherwise first line of tweet
            headline = article.get("title") or tweet.split("\n")[0]
            image_path = create_news_image(headline, article.get("url"))
            # Use tweet as IG caption (it already includes URL + hashtags)
            caption = tweet
            posted = post_to_instagram(image_path, caption)
            if posted:
                print("ğŸ“¸ Instagram post successful.")
            else:
                print("ğŸ“¸ Instagram post skipped/failed.")
        except Exception as e:
            print("âŒ Error during Instagram flow:", e)

    except Exception as e:
        print(f"âŒ Error in main process: {str(e)}")
        raise

if __name__ == "__main__":
    main()
